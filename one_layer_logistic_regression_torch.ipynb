{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dahlia52/Advanced-Statistical-Data-Analysis/blob/main/one_layer_logistic_regression_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3-SXOfswHeBr"
      },
      "id": "3-SXOfswHeBr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sample = 500\n",
        "\n",
        "# 데이터 생성\n",
        "data0 = np.random.randn(num_sample, 2) + (2,2)\n",
        "data1 = np.random.randn(num_sample, 2) + (-2,2)\n",
        "\n",
        "data0 = np.hstack([data0, np.zeros((num_sample, 1), dtype = float)])\n",
        "data1 = np.hstack([data1, np.ones((num_sample, 1), dtype = float)])\n",
        "\n",
        "data = np.vstack([data0, data1])\n",
        "\n",
        "data = torch.tensor(data, dtype = torch.float32) # data를 tensor로 변환\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIOXnaq2Hj8K",
        "outputId": "92808922-e758-49fd-9837-75099a42d67d"
      },
      "id": "EIOXnaq2Hj8K",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08daa2eb",
      "metadata": {
        "id": "08daa2eb"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # learnable linear transformation initialize : 2 -> 1, bias는 알아서 생성\n",
        "        self.linear1 = nn.Linear(2, 1)\n",
        "        # initialized parameter w (w1, w2), b(scalar)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # x -> linear transformation (logit) -> output = sigmoid(probability) -> loss\n",
        "        logit = self.linear1(x)\n",
        "        output = F.sigmoid(-logit)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77ffdba9",
      "metadata": {
        "id": "77ffdba9"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression()\n",
        "loss = nn.BCELoss()\n",
        "#loss = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35771e90",
      "metadata": {
        "id": "35771e90"
      },
      "outputs": [],
      "source": [
        "num_epoch = 100\n",
        "loss_list = list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99887e8a",
      "metadata": {
        "id": "99887e8a",
        "outputId": "1c13ddcd-79bd-4fe2-a874-466bdb866fde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 844.026 / Acc 50.6%\n",
            "Epoch 5: Loss 776.953 / Acc 51.3%\n",
            "Epoch 10: Loss 715.839 / Acc 53.1%\n",
            "Epoch 15: Loss 660.570 / Acc 54.9%\n",
            "Epoch 20: Loss 610.912 / Acc 57.4%\n",
            "Epoch 25: Loss 566.521 / Acc 60.0%\n",
            "Epoch 30: Loss 526.992 / Acc 64.1%\n",
            "Epoch 35: Loss 491.874 / Acc 67.8%\n",
            "Epoch 40: Loss 460.712 / Acc 72.4%\n",
            "Epoch 45: Loss 433.069 / Acc 75.5%\n",
            "Epoch 50: Loss 408.521 / Acc 80.0%\n",
            "Epoch 55: Loss 386.686 / Acc 82.7%\n",
            "Epoch 60: Loss 367.224 / Acc 85.4%\n",
            "Epoch 65: Loss 349.826 / Acc 87.5%\n",
            "Epoch 70: Loss 334.232 / Acc 88.8%\n",
            "Epoch 75: Loss 320.206 / Acc 90.1%\n",
            "Epoch 80: Loss 307.549 / Acc 91.2%\n",
            "Epoch 85: Loss 296.088 / Acc 92.1%\n",
            "Epoch 90: Loss 285.676 / Acc 93.3%\n",
            "Epoch 95: Loss 276.183 / Acc 93.7%\n"
          ]
        }
      ],
      "source": [
        "for i in range(num_epoch):\n",
        "    perm = np.random.permutation(len(data))\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for j in range(len(data)):\n",
        "\n",
        "      # Forward Pass\n",
        "        x = data[perm[j]][:-1]\n",
        "        y = data[perm[j]][-1]\n",
        "\n",
        "        y = y.reshape([1]) # target output\n",
        "        #logit = model.forward(x)\n",
        "        #output = F.sigmoid(logit)\n",
        "        output = model.forward(x) # predicted output\n",
        "\n",
        "        #cost = loss(logit, y)\n",
        "        cost = loss(output, y)\n",
        "\n",
        "      # Backward Pass\n",
        "        optimizer.zero_grad() # gradient를 0으로 초기화\n",
        "        cost.backward() # gradient computation by back-propagation\n",
        "        optimizer.step() # optimizer가 1 step gradient를 optimize (SGD)\n",
        "\n",
        "        total_loss += cost.item()\n",
        "\n",
        "        pred = torch.round(output).item()\n",
        "        count += (pred == y.item())\n",
        "\n",
        "    acc = count/len(data) * 100\n",
        "\n",
        "    loss_list.append(total_loss)\n",
        "\n",
        "    if i % 5 == 0:\n",
        "        print(\"Epoch %d: Loss %.3f / Acc %.1f%%\"%(i,total_loss,acc))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}