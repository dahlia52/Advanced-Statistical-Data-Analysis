{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyONNn6n0PYvBFelo1E0XD7m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dahlia52/Advanced-Statistical-Data-Analysis/blob/main/seq_cell_classification_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wixUzQgSdnj_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST, CIFAR10, CIFAR100\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = './datasets/'\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()]) # 이미지를 텐서로 변환\n",
        "\n",
        "# Prepare Data\n",
        "train_data = MNIST(root = path, train = True, transform = transform, download = True)\n",
        "test_data = MNIST(root = path, train = False, transform = transform, download = True)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True, num_workers = 4)\n",
        "test_loader = DataLoader(dataset = test_data, batch_size = batch_size, shuffle = False, num_workers = 4)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_5pke7ed2up",
        "outputId": "e53517ed-0629-47c9-e0bc-2a92761569fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 53104617.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 114278956.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 46420674.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./datasets/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 16268598.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./datasets/MNIST/raw\n",
            "\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./datasets/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./datasets/\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps:0\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu:0\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKk27eQF1Uzm",
        "outputId": "79ebf3bb-7799-4829-e712-773fbb7d331c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, seq_len, input_size = train_data[0][0].shape # (1,28,28)\n",
        "output_shape = len(train_data.classes) # 10\n",
        "hidden_size = input_size * 2\n",
        "\n",
        "model_name = \"rnn\""
      ],
      "metadata": {
        "id": "DtJat5tA0d77"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST 데이터를 RNN에 적용\n",
        "\n",
        "- row 별 28개의 값을 하나의 데이터 인스턴스로 sequential하게 넣음."
      ],
      "metadata": {
        "id": "Jn39KD3eeuq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.cell = nn.RNNCell(input_size = self.input_size, hidden_size = self.hidden_size)\n",
        "    self.fc = nn.Linear(self.hidden_size, output_shape)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(-1, seq_len, self.input_size).permute((1,0,2)) # (100,1,28,28) -> (100,28,28) -> (28,100,28) => for루프를 위해 transpose\n",
        "    hidden_state = torch.zeros(batch_size, self.hidden_size).to(device) # initial hidden value 설정 (like 수열의 첫 번째 값 설정)\n",
        "    for i in range(seq_len): # 100, 28 = batch_size, input_size\n",
        "       hidden_state = self.cell(x[i], hidden_state) # ith input과 past hidden state를 이용하여 current hidden state update\n",
        "    out = self.fc(hidden_state)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "GjelkjhvA4Jj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.cell = nn.LSTMCell(input_size = self.input_size, hidden_size = self.hidden_size)\n",
        "    self.fc = nn.Linear(self.hidden_size, output_shape)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(-1, seq_len, self.input_size).permute((1,0,2))\n",
        "    hidden_state = torch.zeros(batch_size, self.hidden_size).to(device)\n",
        "    cell_state = torch.zeros(batch_size, self.hidden_size).to(device) # initial cell state 설정\n",
        "\n",
        "    for i in range(seq_len):\n",
        "      hidden_state, cell_state = self.cell(x[i], (hidden_state, cell_state))\n",
        "    out = self.fc(hidden_state)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "JdDM6PY_L_VU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.cell = nn.GRUCell(input_size = self.input_size, hidden_size = self.hidden_size)\n",
        "    self.fc = nn.Linear(self.hidden_size, output_shape)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(-1, seq_len, input_size).permute((1,0,2))\n",
        "    hidden_state = torch.zeros(batch_size, self.hidden_size).to(device)\n",
        "    for i in range(seq_len):\n",
        "      hidden_state = self.cell(x[i], self.hidden_state).to(device)\n",
        "    out = self.fc(hidden_state)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "1yKv4g7jM6IB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "if model_name == \"rnn\":\n",
        "  classifier = RNNClassifier\n",
        "elif model_name == \"lstm\":\n",
        "  classifier = LSTMClassifier\n",
        "elif model_name == \"gru\":\n",
        "  classifier = GRUClassifier"
      ],
      "metadata": {
        "id": "PDOw_SWxOesf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = classifier(input_size, hidden_size).to(device)\n",
        "loss = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "ZhyrEoaRBPM9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtppNd9Jm23h",
        "outputId": "99298f38-6f75-49bf-d1d8-60a1fe4487f4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNClassifier(\n",
              "  (cell): RNNCell(28, 56)\n",
              "  (fc): Linear(in_features=56, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 100\n",
        "train_loss_list, test_loss_list = list(), list()\n",
        "\n",
        "for i in range(num_epoch):\n",
        "  # train\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  count = 0\n",
        "\n",
        "  for batch_idx, (x, y) in enumerate(train_loader):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "\n",
        "    y_est = model.forward(x)\n",
        "    cost = loss(y_est, y)\n",
        "\n",
        "    total_loss += cost.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    pred = torch.argmax(y_est, dim = -1)\n",
        "    count += (pred == y).sum().item()\n",
        "\n",
        "  acc = count / len(train_data)\n",
        "  ave_loss = total_loss / len(train_data)\n",
        "  train_loss_list.append(ave_loss)\n",
        "\n",
        "  if i % 1 == 0:\n",
        "    print(\"\\nEpoch %d Train: Loss %.3f / Accuracy %.3f\"%(i,ave_loss,acc))\n",
        "\n",
        "\n",
        "  # test\n",
        "  model.eval()\n",
        "\n",
        "  total_loss = 0\n",
        "  count = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (x, y) in enumerate(test_loader):\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_est = model.forward(x)\n",
        "      cost = loss(y_est, y)\n",
        "\n",
        "      total_loss += cost.item()\n",
        "\n",
        "      pred = torch.argmax(y_est, dim = -1)\n",
        "      count += (pred == y).sum().item()\n",
        "\n",
        "    acc = count / len(test_data)\n",
        "    avg_loss = total_loss / len(test_data)\n",
        "\n",
        "    test_loss_list.append(avg_loss)\n",
        "\n",
        "    if i % 1 == 0:\n",
        "      print(\"Epoch %d Test: Loss %.3f / Accuracy %.3f\"%(i,avg_loss,acc))"
      ],
      "metadata": {
        "id": "v62NzkRBOhXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0190c711-b425-4853-a9f5-38847570a926"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 Train: Loss 0.893 / Accuracy 0.686\n",
            "Epoch 0 Test: Loss 0.780 / Accuracy 0.738\n",
            "\n",
            "Epoch 1 Train: Loss 0.687 / Accuracy 0.768\n",
            "Epoch 1 Test: Loss 0.603 / Accuracy 0.802\n",
            "\n",
            "Epoch 2 Train: Loss 0.549 / Accuracy 0.824\n",
            "Epoch 2 Test: Loss 0.510 / Accuracy 0.835\n",
            "\n",
            "Epoch 3 Train: Loss 0.440 / Accuracy 0.866\n",
            "Epoch 3 Test: Loss 0.405 / Accuracy 0.873\n",
            "\n",
            "Epoch 4 Train: Loss 0.367 / Accuracy 0.892\n",
            "Epoch 4 Test: Loss 0.311 / Accuracy 0.910\n",
            "\n",
            "Epoch 5 Train: Loss 0.321 / Accuracy 0.907\n",
            "Epoch 5 Test: Loss 0.343 / Accuracy 0.895\n",
            "\n",
            "Epoch 6 Train: Loss 0.286 / Accuracy 0.916\n",
            "Epoch 6 Test: Loss 0.255 / Accuracy 0.927\n",
            "\n",
            "Epoch 7 Train: Loss 0.258 / Accuracy 0.927\n",
            "Epoch 7 Test: Loss 0.246 / Accuracy 0.932\n",
            "\n",
            "Epoch 8 Train: Loss 0.240 / Accuracy 0.930\n",
            "Epoch 8 Test: Loss 0.224 / Accuracy 0.941\n",
            "\n",
            "Epoch 9 Train: Loss 0.216 / Accuracy 0.938\n",
            "Epoch 9 Test: Loss 0.212 / Accuracy 0.943\n",
            "\n",
            "Epoch 10 Train: Loss 0.201 / Accuracy 0.943\n",
            "Epoch 10 Test: Loss 0.207 / Accuracy 0.943\n",
            "\n",
            "Epoch 11 Train: Loss 0.196 / Accuracy 0.943\n",
            "Epoch 11 Test: Loss 0.189 / Accuracy 0.946\n",
            "\n",
            "Epoch 12 Train: Loss 0.184 / Accuracy 0.948\n",
            "Epoch 12 Test: Loss 0.180 / Accuracy 0.950\n",
            "\n",
            "Epoch 13 Train: Loss 0.175 / Accuracy 0.950\n",
            "Epoch 13 Test: Loss 0.185 / Accuracy 0.949\n",
            "\n",
            "Epoch 14 Train: Loss 0.169 / Accuracy 0.952\n",
            "Epoch 14 Test: Loss 0.189 / Accuracy 0.947\n",
            "\n",
            "Epoch 15 Train: Loss 0.157 / Accuracy 0.956\n",
            "Epoch 15 Test: Loss 0.160 / Accuracy 0.956\n",
            "\n",
            "Epoch 16 Train: Loss 0.155 / Accuracy 0.956\n",
            "Epoch 16 Test: Loss 0.173 / Accuracy 0.952\n",
            "\n",
            "Epoch 17 Train: Loss 0.149 / Accuracy 0.958\n",
            "Epoch 17 Test: Loss 0.152 / Accuracy 0.959\n",
            "\n",
            "Epoch 18 Train: Loss 0.143 / Accuracy 0.961\n",
            "Epoch 18 Test: Loss 0.146 / Accuracy 0.962\n",
            "\n",
            "Epoch 19 Train: Loss 0.142 / Accuracy 0.960\n",
            "Epoch 19 Test: Loss 0.161 / Accuracy 0.959\n",
            "\n",
            "Epoch 20 Train: Loss 0.138 / Accuracy 0.961\n",
            "Epoch 20 Test: Loss 0.154 / Accuracy 0.960\n",
            "\n",
            "Epoch 21 Train: Loss 0.135 / Accuracy 0.963\n",
            "Epoch 21 Test: Loss 0.145 / Accuracy 0.960\n",
            "\n",
            "Epoch 22 Train: Loss 0.125 / Accuracy 0.965\n",
            "Epoch 22 Test: Loss 0.140 / Accuracy 0.962\n",
            "\n",
            "Epoch 23 Train: Loss 0.131 / Accuracy 0.963\n",
            "Epoch 23 Test: Loss 0.146 / Accuracy 0.961\n",
            "\n",
            "Epoch 24 Train: Loss 0.118 / Accuracy 0.967\n",
            "Epoch 24 Test: Loss 0.166 / Accuracy 0.957\n",
            "\n",
            "Epoch 25 Train: Loss 0.116 / Accuracy 0.968\n",
            "Epoch 25 Test: Loss 0.136 / Accuracy 0.964\n",
            "\n",
            "Epoch 26 Train: Loss 0.115 / Accuracy 0.968\n",
            "Epoch 26 Test: Loss 0.136 / Accuracy 0.962\n",
            "\n",
            "Epoch 27 Train: Loss 0.119 / Accuracy 0.966\n",
            "Epoch 27 Test: Loss 0.138 / Accuracy 0.962\n",
            "\n",
            "Epoch 28 Train: Loss 0.109 / Accuracy 0.970\n",
            "Epoch 28 Test: Loss 0.121 / Accuracy 0.967\n",
            "\n",
            "Epoch 29 Train: Loss 0.110 / Accuracy 0.969\n",
            "Epoch 29 Test: Loss 0.122 / Accuracy 0.967\n",
            "\n",
            "Epoch 30 Train: Loss 0.103 / Accuracy 0.971\n",
            "Epoch 30 Test: Loss 0.125 / Accuracy 0.966\n",
            "\n",
            "Epoch 31 Train: Loss 0.106 / Accuracy 0.970\n",
            "Epoch 31 Test: Loss 0.114 / Accuracy 0.968\n",
            "\n",
            "Epoch 32 Train: Loss 0.101 / Accuracy 0.972\n",
            "Epoch 32 Test: Loss 0.125 / Accuracy 0.967\n",
            "\n",
            "Epoch 33 Train: Loss 0.101 / Accuracy 0.971\n",
            "Epoch 33 Test: Loss 0.120 / Accuracy 0.970\n",
            "\n",
            "Epoch 34 Train: Loss 0.097 / Accuracy 0.973\n",
            "Epoch 34 Test: Loss 0.117 / Accuracy 0.966\n",
            "\n",
            "Epoch 35 Train: Loss 0.102 / Accuracy 0.971\n",
            "Epoch 35 Test: Loss 0.144 / Accuracy 0.961\n",
            "\n",
            "Epoch 36 Train: Loss 0.095 / Accuracy 0.973\n",
            "Epoch 36 Test: Loss 0.115 / Accuracy 0.970\n",
            "\n",
            "Epoch 37 Train: Loss 0.091 / Accuracy 0.975\n",
            "Epoch 37 Test: Loss 0.114 / Accuracy 0.970\n",
            "\n",
            "Epoch 38 Train: Loss 0.096 / Accuracy 0.973\n",
            "Epoch 38 Test: Loss 0.113 / Accuracy 0.970\n",
            "\n",
            "Epoch 39 Train: Loss 0.092 / Accuracy 0.974\n",
            "Epoch 39 Test: Loss 0.111 / Accuracy 0.969\n",
            "\n",
            "Epoch 40 Train: Loss 0.088 / Accuracy 0.974\n",
            "Epoch 40 Test: Loss 0.124 / Accuracy 0.967\n",
            "\n",
            "Epoch 41 Train: Loss 0.089 / Accuracy 0.975\n",
            "Epoch 41 Test: Loss 0.117 / Accuracy 0.970\n",
            "\n",
            "Epoch 42 Train: Loss 0.090 / Accuracy 0.974\n",
            "Epoch 42 Test: Loss 0.111 / Accuracy 0.972\n",
            "\n",
            "Epoch 43 Train: Loss 0.085 / Accuracy 0.975\n",
            "Epoch 43 Test: Loss 0.117 / Accuracy 0.969\n",
            "\n",
            "Epoch 44 Train: Loss 0.089 / Accuracy 0.975\n",
            "Epoch 44 Test: Loss 0.109 / Accuracy 0.972\n",
            "\n",
            "Epoch 45 Train: Loss 0.082 / Accuracy 0.977\n",
            "Epoch 45 Test: Loss 0.110 / Accuracy 0.970\n",
            "\n",
            "Epoch 46 Train: Loss 0.086 / Accuracy 0.976\n",
            "Epoch 46 Test: Loss 0.114 / Accuracy 0.969\n",
            "\n",
            "Epoch 47 Train: Loss 0.086 / Accuracy 0.975\n",
            "Epoch 47 Test: Loss 0.127 / Accuracy 0.967\n",
            "\n",
            "Epoch 48 Train: Loss 0.082 / Accuracy 0.977\n",
            "Epoch 48 Test: Loss 0.149 / Accuracy 0.961\n",
            "\n",
            "Epoch 49 Train: Loss 0.088 / Accuracy 0.974\n",
            "Epoch 49 Test: Loss 0.116 / Accuracy 0.971\n",
            "\n",
            "Epoch 50 Train: Loss 0.080 / Accuracy 0.977\n",
            "Epoch 50 Test: Loss 0.109 / Accuracy 0.972\n",
            "\n",
            "Epoch 51 Train: Loss 0.080 / Accuracy 0.977\n",
            "Epoch 51 Test: Loss 0.109 / Accuracy 0.972\n",
            "\n",
            "Epoch 52 Train: Loss 0.084 / Accuracy 0.976\n",
            "Epoch 52 Test: Loss 0.104 / Accuracy 0.973\n",
            "\n",
            "Epoch 53 Train: Loss 0.079 / Accuracy 0.978\n",
            "Epoch 53 Test: Loss 0.139 / Accuracy 0.964\n",
            "\n",
            "Epoch 54 Train: Loss 0.082 / Accuracy 0.977\n",
            "Epoch 54 Test: Loss 0.103 / Accuracy 0.973\n",
            "\n",
            "Epoch 55 Train: Loss 0.078 / Accuracy 0.978\n",
            "Epoch 55 Test: Loss 0.107 / Accuracy 0.973\n",
            "\n",
            "Epoch 56 Train: Loss 0.076 / Accuracy 0.979\n",
            "Epoch 56 Test: Loss 0.105 / Accuracy 0.973\n",
            "\n",
            "Epoch 57 Train: Loss 0.076 / Accuracy 0.979\n",
            "Epoch 57 Test: Loss 0.098 / Accuracy 0.973\n",
            "\n",
            "Epoch 58 Train: Loss 0.078 / Accuracy 0.978\n",
            "Epoch 58 Test: Loss 0.112 / Accuracy 0.971\n",
            "\n",
            "Epoch 59 Train: Loss 0.077 / Accuracy 0.979\n",
            "Epoch 59 Test: Loss 0.113 / Accuracy 0.970\n",
            "\n",
            "Epoch 60 Train: Loss 0.074 / Accuracy 0.978\n",
            "Epoch 60 Test: Loss 0.113 / Accuracy 0.972\n",
            "\n",
            "Epoch 61 Train: Loss 0.070 / Accuracy 0.980\n",
            "Epoch 61 Test: Loss 0.113 / Accuracy 0.972\n",
            "\n",
            "Epoch 62 Train: Loss 0.078 / Accuracy 0.978\n",
            "Epoch 62 Test: Loss 0.113 / Accuracy 0.972\n",
            "\n",
            "Epoch 63 Train: Loss 0.079 / Accuracy 0.978\n",
            "Epoch 63 Test: Loss 0.113 / Accuracy 0.971\n",
            "\n",
            "Epoch 64 Train: Loss 0.075 / Accuracy 0.979\n",
            "Epoch 64 Test: Loss 0.121 / Accuracy 0.970\n",
            "\n",
            "Epoch 65 Train: Loss 0.073 / Accuracy 0.979\n",
            "Epoch 65 Test: Loss 0.117 / Accuracy 0.970\n",
            "\n",
            "Epoch 66 Train: Loss 0.071 / Accuracy 0.980\n",
            "Epoch 66 Test: Loss 0.115 / Accuracy 0.972\n",
            "\n",
            "Epoch 67 Train: Loss 0.076 / Accuracy 0.979\n",
            "Epoch 67 Test: Loss 0.162 / Accuracy 0.958\n",
            "\n",
            "Epoch 68 Train: Loss 0.076 / Accuracy 0.978\n",
            "Epoch 68 Test: Loss 0.130 / Accuracy 0.967\n",
            "\n",
            "Epoch 69 Train: Loss 0.074 / Accuracy 0.979\n",
            "Epoch 69 Test: Loss 0.114 / Accuracy 0.970\n",
            "\n",
            "Epoch 70 Train: Loss 0.070 / Accuracy 0.980\n",
            "Epoch 70 Test: Loss 0.114 / Accuracy 0.970\n",
            "\n",
            "Epoch 71 Train: Loss 0.074 / Accuracy 0.979\n",
            "Epoch 71 Test: Loss 0.115 / Accuracy 0.969\n",
            "\n",
            "Epoch 72 Train: Loss 0.066 / Accuracy 0.982\n",
            "Epoch 72 Test: Loss 0.135 / Accuracy 0.964\n",
            "\n",
            "Epoch 73 Train: Loss 0.072 / Accuracy 0.979\n",
            "Epoch 73 Test: Loss 0.100 / Accuracy 0.974\n",
            "\n",
            "Epoch 74 Train: Loss 0.072 / Accuracy 0.980\n",
            "Epoch 74 Test: Loss 0.100 / Accuracy 0.974\n",
            "\n",
            "Epoch 75 Train: Loss 0.072 / Accuracy 0.980\n",
            "Epoch 75 Test: Loss 0.124 / Accuracy 0.969\n",
            "\n",
            "Epoch 76 Train: Loss 0.068 / Accuracy 0.981\n",
            "Epoch 76 Test: Loss 0.112 / Accuracy 0.972\n",
            "\n",
            "Epoch 77 Train: Loss 0.070 / Accuracy 0.980\n",
            "Epoch 77 Test: Loss 0.104 / Accuracy 0.975\n",
            "\n",
            "Epoch 78 Train: Loss 0.068 / Accuracy 0.981\n",
            "Epoch 78 Test: Loss 0.117 / Accuracy 0.970\n",
            "\n",
            "Epoch 79 Train: Loss 0.064 / Accuracy 0.981\n",
            "Epoch 79 Test: Loss 0.125 / Accuracy 0.969\n",
            "\n",
            "Epoch 80 Train: Loss 0.070 / Accuracy 0.980\n",
            "Epoch 80 Test: Loss 0.145 / Accuracy 0.965\n",
            "\n",
            "Epoch 81 Train: Loss 0.078 / Accuracy 0.977\n",
            "Epoch 81 Test: Loss 0.097 / Accuracy 0.976\n",
            "\n",
            "Epoch 82 Train: Loss 0.069 / Accuracy 0.980\n",
            "Epoch 82 Test: Loss 0.120 / Accuracy 0.970\n",
            "\n",
            "Epoch 83 Train: Loss 0.068 / Accuracy 0.980\n",
            "Epoch 83 Test: Loss 0.130 / Accuracy 0.967\n",
            "\n",
            "Epoch 84 Train: Loss 0.065 / Accuracy 0.982\n",
            "Epoch 84 Test: Loss 0.109 / Accuracy 0.974\n",
            "\n",
            "Epoch 85 Train: Loss 0.075 / Accuracy 0.979\n",
            "Epoch 85 Test: Loss 0.122 / Accuracy 0.972\n",
            "\n",
            "Epoch 86 Train: Loss 0.068 / Accuracy 0.980\n",
            "Epoch 86 Test: Loss 0.109 / Accuracy 0.972\n",
            "\n",
            "Epoch 87 Train: Loss 0.073 / Accuracy 0.979\n",
            "Epoch 87 Test: Loss 0.107 / Accuracy 0.973\n",
            "\n",
            "Epoch 88 Train: Loss 0.062 / Accuracy 0.982\n",
            "Epoch 88 Test: Loss 0.108 / Accuracy 0.973\n",
            "\n",
            "Epoch 89 Train: Loss 0.066 / Accuracy 0.981\n",
            "Epoch 89 Test: Loss 0.109 / Accuracy 0.973\n",
            "\n",
            "Epoch 90 Train: Loss 0.063 / Accuracy 0.982\n",
            "Epoch 90 Test: Loss 0.109 / Accuracy 0.973\n",
            "\n",
            "Epoch 91 Train: Loss 0.077 / Accuracy 0.978\n",
            "Epoch 91 Test: Loss 0.201 / Accuracy 0.949\n",
            "\n",
            "Epoch 92 Train: Loss 0.065 / Accuracy 0.981\n",
            "Epoch 92 Test: Loss 0.117 / Accuracy 0.971\n",
            "\n",
            "Epoch 93 Train: Loss 0.068 / Accuracy 0.980\n",
            "Epoch 93 Test: Loss 0.136 / Accuracy 0.965\n",
            "\n",
            "Epoch 94 Train: Loss 0.070 / Accuracy 0.980\n",
            "Epoch 94 Test: Loss 0.114 / Accuracy 0.971\n",
            "\n",
            "Epoch 95 Train: Loss 0.066 / Accuracy 0.981\n",
            "Epoch 95 Test: Loss 0.105 / Accuracy 0.975\n",
            "\n",
            "Epoch 96 Train: Loss 0.063 / Accuracy 0.981\n",
            "Epoch 96 Test: Loss 0.114 / Accuracy 0.971\n",
            "\n",
            "Epoch 97 Train: Loss 0.060 / Accuracy 0.983\n",
            "Epoch 97 Test: Loss 0.105 / Accuracy 0.973\n",
            "\n",
            "Epoch 98 Train: Loss 0.071 / Accuracy 0.980\n",
            "Epoch 98 Test: Loss 0.105 / Accuracy 0.974\n",
            "\n",
            "Epoch 99 Train: Loss 0.065 / Accuracy 0.981\n",
            "Epoch 99 Test: Loss 0.116 / Accuracy 0.972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_parameter = 0\n",
        "for parameter in model.parameters():\n",
        "  print(parameter.shape)\n",
        "  num_parameter += np.prod(parameter.size())\n",
        "print(num_parameter)"
      ],
      "metadata": {
        "id": "ryAsRqd6Ohap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83cfdd5d-0787-4a17-8187-75d0c80037b8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([56, 28])\n",
            "torch.Size([56, 56])\n",
            "torch.Size([56])\n",
            "torch.Size([56])\n",
            "torch.Size([10, 56])\n",
            "torch.Size([10])\n",
            "5386\n"
          ]
        }
      ]
    }
  ]
}